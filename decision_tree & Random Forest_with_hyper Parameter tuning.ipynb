{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.6</td>\n",
       "      <td>0.191</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.1</td>\n",
       "      <td>1.441</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>166</td>\n",
       "      <td>72</td>\n",
       "      <td>19</td>\n",
       "      <td>175</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.587</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.484</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>84</td>\n",
       "      <td>47</td>\n",
       "      <td>230</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.551</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7</td>\n",
       "      <td>107</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>83</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.183</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>70</td>\n",
       "      <td>30</td>\n",
       "      <td>96</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>88</td>\n",
       "      <td>41</td>\n",
       "      <td>235</td>\n",
       "      <td>39.3</td>\n",
       "      <td>0.704</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.4</td>\n",
       "      <td>0.388</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>196</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.451</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>119</td>\n",
       "      <td>80</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11</td>\n",
       "      <td>143</td>\n",
       "      <td>94</td>\n",
       "      <td>33</td>\n",
       "      <td>146</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.254</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>125</td>\n",
       "      <td>70</td>\n",
       "      <td>26</td>\n",
       "      <td>115</td>\n",
       "      <td>31.1</td>\n",
       "      <td>0.205</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>147</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.257</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>15</td>\n",
       "      <td>140</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0.487</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13</td>\n",
       "      <td>145</td>\n",
       "      <td>82</td>\n",
       "      <td>19</td>\n",
       "      <td>110</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>117</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.337</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>160</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.453</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.293</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>11</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>37</td>\n",
       "      <td>150</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.785</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>44</td>\n",
       "      <td>20</td>\n",
       "      <td>94</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.400</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>58</td>\n",
       "      <td>18</td>\n",
       "      <td>116</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.219</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>9</td>\n",
       "      <td>140</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.734</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>13</td>\n",
       "      <td>153</td>\n",
       "      <td>88</td>\n",
       "      <td>37</td>\n",
       "      <td>140</td>\n",
       "      <td>40.6</td>\n",
       "      <td>1.174</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>105</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>94</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>49.3</td>\n",
       "      <td>0.358</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>74</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1.096</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>3</td>\n",
       "      <td>187</td>\n",
       "      <td>70</td>\n",
       "      <td>22</td>\n",
       "      <td>200</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.408</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>6</td>\n",
       "      <td>162</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.178</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>1.182</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>78</td>\n",
       "      <td>39</td>\n",
       "      <td>74</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.261</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>62</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.223</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>510</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>8</td>\n",
       "      <td>154</td>\n",
       "      <td>78</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.443</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>88</td>\n",
       "      <td>39</td>\n",
       "      <td>110</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>7</td>\n",
       "      <td>137</td>\n",
       "      <td>90</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.391</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.3</td>\n",
       "      <td>0.258</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.197</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>6</td>\n",
       "      <td>190</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.278</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>9</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.142</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "5              5      116             74              0        0  25.6   \n",
       "6              3       78             50             32       88  31.0   \n",
       "7             10      115              0              0        0  35.3   \n",
       "8              2      197             70             45      543  30.5   \n",
       "9              8      125             96              0        0   0.0   \n",
       "10             4      110             92              0        0  37.6   \n",
       "11            10      168             74              0        0  38.0   \n",
       "12            10      139             80              0        0  27.1   \n",
       "13             1      189             60             23      846  30.1   \n",
       "14             5      166             72             19      175  25.8   \n",
       "15             7      100              0              0        0  30.0   \n",
       "16             0      118             84             47      230  45.8   \n",
       "17             7      107             74              0        0  29.6   \n",
       "18             1      103             30             38       83  43.3   \n",
       "19             1      115             70             30       96  34.6   \n",
       "20             3      126             88             41      235  39.3   \n",
       "21             8       99             84              0        0  35.4   \n",
       "22             7      196             90              0        0  39.8   \n",
       "23             9      119             80             35        0  29.0   \n",
       "24            11      143             94             33      146  36.6   \n",
       "25            10      125             70             26      115  31.1   \n",
       "26             7      147             76              0        0  39.4   \n",
       "27             1       97             66             15      140  23.2   \n",
       "28            13      145             82             19      110  22.2   \n",
       "29             5      117             92              0        0  34.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "738            2       99             60             17      160  36.6   \n",
       "739            1      102             74              0        0  39.5   \n",
       "740           11      120             80             37      150  42.3   \n",
       "741            3      102             44             20       94  30.8   \n",
       "742            1      109             58             18      116  28.5   \n",
       "743            9      140             94              0        0  32.7   \n",
       "744           13      153             88             37      140  40.6   \n",
       "745           12      100             84             33      105  30.0   \n",
       "746            1      147             94             41        0  49.3   \n",
       "747            1       81             74             41       57  46.3   \n",
       "748            3      187             70             22      200  36.4   \n",
       "749            6      162             62              0        0  24.3   \n",
       "750            4      136             70              0        0  31.2   \n",
       "751            1      121             78             39       74  39.0   \n",
       "752            3      108             62             24        0  26.0   \n",
       "753            0      181             88             44      510  43.3   \n",
       "754            8      154             78             32        0  32.4   \n",
       "755            1      128             88             39      110  36.5   \n",
       "756            7      137             90             41        0  32.0   \n",
       "757            0      123             72              0        0  36.3   \n",
       "758            1      106             76              0        0  37.5   \n",
       "759            6      190             92              0        0  35.5   \n",
       "760            2       88             58             26       16  28.4   \n",
       "761            9      170             74             31        0  44.0   \n",
       "762            9       89             62              0        0  22.5   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "5                       0.201   30        0  \n",
       "6                       0.248   26        1  \n",
       "7                       0.134   29        0  \n",
       "8                       0.158   53        1  \n",
       "9                       0.232   54        1  \n",
       "10                      0.191   30        0  \n",
       "11                      0.537   34        1  \n",
       "12                      1.441   57        0  \n",
       "13                      0.398   59        1  \n",
       "14                      0.587   51        1  \n",
       "15                      0.484   32        1  \n",
       "16                      0.551   31        1  \n",
       "17                      0.254   31        1  \n",
       "18                      0.183   33        0  \n",
       "19                      0.529   32        1  \n",
       "20                      0.704   27        0  \n",
       "21                      0.388   50        0  \n",
       "22                      0.451   41        1  \n",
       "23                      0.263   29        1  \n",
       "24                      0.254   51        1  \n",
       "25                      0.205   41        1  \n",
       "26                      0.257   43        1  \n",
       "27                      0.487   22        0  \n",
       "28                      0.245   57        0  \n",
       "29                      0.337   38        0  \n",
       "..                        ...  ...      ...  \n",
       "738                     0.453   21        0  \n",
       "739                     0.293   42        1  \n",
       "740                     0.785   48        1  \n",
       "741                     0.400   26        0  \n",
       "742                     0.219   22        0  \n",
       "743                     0.734   45        1  \n",
       "744                     1.174   39        0  \n",
       "745                     0.488   46        0  \n",
       "746                     0.358   27        1  \n",
       "747                     1.096   32        0  \n",
       "748                     0.408   36        1  \n",
       "749                     0.178   50        1  \n",
       "750                     1.182   22        1  \n",
       "751                     0.261   28        0  \n",
       "752                     0.223   25        0  \n",
       "753                     0.222   26        1  \n",
       "754                     0.443   45        1  \n",
       "755                     1.057   37        1  \n",
       "756                     0.391   39        0  \n",
       "757                     0.258   52        1  \n",
       "758                     0.197   26        0  \n",
       "759                     0.278   66        1  \n",
       "760                     0.766   22        0  \n",
       "761                     0.403   43        1  \n",
       "762                     0.142   33        0  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "diabetes_df = pd.read_csv('diabetes.csv')\n",
    "diabetes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>7</td>\n",
       "      <td>152</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.337</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>74</td>\n",
       "      <td>50</td>\n",
       "      <td>204</td>\n",
       "      <td>37.4</td>\n",
       "      <td>0.399</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.2</td>\n",
       "      <td>0.270</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>52</td>\n",
       "      <td>26</td>\n",
       "      <td>63</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0.318</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "      <td>74</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.197</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>90</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>42.1</td>\n",
       "      <td>0.371</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.140</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>117</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.1</td>\n",
       "      <td>0.337</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>3</td>\n",
       "      <td>111</td>\n",
       "      <td>90</td>\n",
       "      <td>12</td>\n",
       "      <td>78</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.495</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>68</td>\n",
       "      <td>19</td>\n",
       "      <td>180</td>\n",
       "      <td>30.5</td>\n",
       "      <td>1.391</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>1</td>\n",
       "      <td>167</td>\n",
       "      <td>74</td>\n",
       "      <td>17</td>\n",
       "      <td>144</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.447</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.222</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>3</td>\n",
       "      <td>122</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.254</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>85</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0.375</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "      <td>70</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>0.204</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.088</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>4</td>\n",
       "      <td>132</td>\n",
       "      <td>86</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.419</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.5</td>\n",
       "      <td>1.781</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>6</td>\n",
       "      <td>124</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.6</td>\n",
       "      <td>0.368</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.455</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.078</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.624</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>6</td>\n",
       "      <td>195</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.328</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>4</td>\n",
       "      <td>129</td>\n",
       "      <td>60</td>\n",
       "      <td>12</td>\n",
       "      <td>231</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.527</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>64</td>\n",
       "      <td>36</td>\n",
       "      <td>100</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.600</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>72</td>\n",
       "      <td>21</td>\n",
       "      <td>168</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.123</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>58</td>\n",
       "      <td>36</td>\n",
       "      <td>94</td>\n",
       "      <td>33.3</td>\n",
       "      <td>0.261</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "      <td>39</td>\n",
       "      <td>72</td>\n",
       "      <td>43.4</td>\n",
       "      <td>1.021</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>3</td>\n",
       "      <td>182</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.345</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.177</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>3</td>\n",
       "      <td>89</td>\n",
       "      <td>74</td>\n",
       "      <td>16</td>\n",
       "      <td>85</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.551</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>7</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.305</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>140</td>\n",
       "      <td>33.8</td>\n",
       "      <td>0.088</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>7</td>\n",
       "      <td>150</td>\n",
       "      <td>78</td>\n",
       "      <td>29</td>\n",
       "      <td>126</td>\n",
       "      <td>35.2</td>\n",
       "      <td>0.692</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>7</td>\n",
       "      <td>168</td>\n",
       "      <td>88</td>\n",
       "      <td>42</td>\n",
       "      <td>321</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.787</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>5</td>\n",
       "      <td>117</td>\n",
       "      <td>86</td>\n",
       "      <td>30</td>\n",
       "      <td>105</td>\n",
       "      <td>39.1</td>\n",
       "      <td>0.251</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>5</td>\n",
       "      <td>106</td>\n",
       "      <td>82</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.286</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>84</td>\n",
       "      <td>33</td>\n",
       "      <td>474</td>\n",
       "      <td>35.7</td>\n",
       "      <td>0.258</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>10</td>\n",
       "      <td>111</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.141</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>32.3</td>\n",
       "      <td>0.660</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>13</td>\n",
       "      <td>106</td>\n",
       "      <td>72</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.178</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0.277</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>60</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>0.133</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>170</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.692</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0.270</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "      <td>64</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0.284</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>4</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>39</td>\n",
       "      <td>744</td>\n",
       "      <td>36.7</td>\n",
       "      <td>2.329</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>52</td>\n",
       "      <td>27</td>\n",
       "      <td>540</td>\n",
       "      <td>38.7</td>\n",
       "      <td>0.240</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.9</td>\n",
       "      <td>0.334</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>62</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.223</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>64</td>\n",
       "      <td>19</td>\n",
       "      <td>82</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.299</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>160</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.453</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>10</td>\n",
       "      <td>133</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.245</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>8</td>\n",
       "      <td>176</td>\n",
       "      <td>90</td>\n",
       "      <td>34</td>\n",
       "      <td>300</td>\n",
       "      <td>33.7</td>\n",
       "      <td>0.467</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.2</td>\n",
       "      <td>0.237</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.307</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>70</td>\n",
       "      <td>32</td>\n",
       "      <td>66</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.187</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "155            7      152             88             44        0  50.0   \n",
       "150            1      136             74             50      204  37.4   \n",
       "78             0      131              0              0        0  43.2   \n",
       "9              8      125             96              0        0   0.0   \n",
       "142            2      108             52             26       63  32.5   \n",
       "321            3      112             74             30        0  31.6   \n",
       "580            0      151             90             46        0  42.1   \n",
       "75             1        0             48             20        0  24.7   \n",
       "29             5      117             92              0        0  34.1   \n",
       "169            3      111             90             12       78  28.4   \n",
       "308            0      128             68             19      180  30.5   \n",
       "646            1      167             74             17      144  23.4   \n",
       "100            1      163             72              0        0  39.0   \n",
       "272            3      122             78              0        0  23.0   \n",
       "211            0      147             85             54        0  42.8   \n",
       "550            1      116             70             28        0  27.4   \n",
       "598            1      173             74              0        0  36.8   \n",
       "479            4      132             86             31        0  28.0   \n",
       "767            1       93             70             31        0  30.4   \n",
       "58             0      146             82              0        0  40.5   \n",
       "366            6      124             72              0        0  27.6   \n",
       "653            2      120             54              0        0  26.8   \n",
       "268            0      102             52              0        0  25.1   \n",
       "418            1       83             68              0        0  18.2   \n",
       "675            6      195             70              0        0  30.9   \n",
       "320            4      129             60             12      231  27.5   \n",
       "467            0       97             64             36      100  36.8   \n",
       "325            1      157             72             21      168  25.6   \n",
       "127            1      118             58             36       94  33.3   \n",
       "379            0       93            100             39       72  43.4   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "317            3      182             74              0        0  30.5   \n",
       "705            6       80             80             36        0  39.8   \n",
       "431            3       89             74             16       85  30.4   \n",
       "49             7      105              0              0        0   0.0   \n",
       "135            2      125             60             20      140  33.8   \n",
       "603            7      150             78             29      126  35.2   \n",
       "4              0      137             40             35      168  43.1   \n",
       "612            7      168             88             42      321  38.2   \n",
       "723            5      117             86             30      105  39.1   \n",
       "141            5      106             82             30        0  39.5   \n",
       "415            3      173             84             33      474  35.7   \n",
       "667           10      111             70             27        0  27.5   \n",
       "386            5      116             74             29        0  32.3   \n",
       "86            13      106             72             54        0  36.6   \n",
       "93             4      134             72              0        0  23.8   \n",
       "649            0      107             60             25        0  26.4   \n",
       "507            1      130             60             23      170  28.6   \n",
       "570            3       78             70              0        0  32.5   \n",
       "316            3       99             80             11       64  19.3   \n",
       "228            4      197             70             39      744  36.7   \n",
       "655            2      155             52             27      540  38.7   \n",
       "280            0      146             70              0        0  37.9   \n",
       "752            3      108             62             24        0  26.0   \n",
       "526            1       97             64             19       82  18.2   \n",
       "738            2       99             60             17      160  36.6   \n",
       "578           10      133             68              0        0  27.0   \n",
       "53             8      176             90             34      300  33.7   \n",
       "350            4       92             80              0        0  42.2   \n",
       "79             2      112             66             22        0  25.0   \n",
       "520            2       68             70             32       66  25.0   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  \n",
       "155                     0.337   36  \n",
       "150                     0.399   24  \n",
       "78                      0.270   26  \n",
       "9                       0.232   54  \n",
       "142                     0.318   22  \n",
       "321                     0.197   25  \n",
       "580                     0.371   21  \n",
       "75                      0.140   22  \n",
       "29                      0.337   38  \n",
       "169                     0.495   29  \n",
       "308                     1.391   25  \n",
       "646                     0.447   33  \n",
       "100                     1.222   33  \n",
       "272                     0.254   40  \n",
       "211                     0.375   24  \n",
       "550                     0.204   21  \n",
       "598                     0.088   38  \n",
       "479                     0.419   63  \n",
       "767                     0.315   23  \n",
       "58                      1.781   44  \n",
       "366                     0.368   29  \n",
       "653                     0.455   27  \n",
       "268                     0.078   21  \n",
       "418                     0.624   27  \n",
       "675                     0.328   31  \n",
       "320                     0.527   31  \n",
       "467                     0.600   25  \n",
       "325                     0.123   24  \n",
       "127                     0.261   23  \n",
       "379                     1.021   35  \n",
       "..                        ...  ...  \n",
       "317                     0.345   29  \n",
       "705                     0.177   28  \n",
       "431                     0.551   38  \n",
       "49                      0.305   24  \n",
       "135                     0.088   31  \n",
       "603                     0.692   54  \n",
       "4                       2.288   33  \n",
       "612                     0.787   40  \n",
       "723                     0.251   42  \n",
       "141                     0.286   38  \n",
       "415                     0.258   22  \n",
       "667                     0.141   40  \n",
       "386                     0.660   35  \n",
       "86                      0.178   45  \n",
       "93                      0.277   60  \n",
       "649                     0.133   23  \n",
       "507                     0.692   21  \n",
       "570                     0.270   39  \n",
       "316                     0.284   30  \n",
       "228                     2.329   31  \n",
       "655                     0.240   25  \n",
       "280                     0.334   28  \n",
       "752                     0.223   25  \n",
       "526                     0.299   21  \n",
       "738                     0.453   21  \n",
       "578                     0.245   36  \n",
       "53                      0.467   58  \n",
       "350                     0.237   29  \n",
       "79                      0.307   24  \n",
       "520                     0.187   25  \n",
       "\n",
       "[537 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import  train_test_split\n",
    "y = diabetes_df['Outcome']\n",
    "diabetes_df.drop(columns='Outcome', inplace=True)\n",
    "X_train, X_test, y_train, y_test=train_test_split(diabetes_df,y,test_size=0.3, random_state=100)\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree= DecisionTreeClassifier()\n",
    "model=decision_tree.fit(X_train,y_train)\n",
    "predict_model=decision_tree.predict( X_test)\n",
    "predict_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  predicted\n",
       "173       0          0\n",
       "253       0          0\n",
       "207       1          1\n",
       "737       0          0\n",
       "191       0          0\n",
       "754       1          1\n",
       "159       1          1\n",
       "448       1          1\n",
       "359       1          1\n",
       "651       0          0\n",
       "543       0          0\n",
       "175       1          1\n",
       "657       0          1\n",
       "613       0          0\n",
       "40        0          1\n",
       "358       0          0\n",
       "156       0          0\n",
       "19        1          1\n",
       "213       1          1\n",
       "559       0          0\n",
       "73        0          0\n",
       "97        0          0\n",
       "388       1          1\n",
       "546       1          1\n",
       "354       0          0\n",
       "72        1          1\n",
       "486       0          0\n",
       "711       0          1\n",
       "125       1          1\n",
       "666       1          1\n",
       "..      ...        ...\n",
       "455       1          1\n",
       "351       0          0\n",
       "491       0          0\n",
       "673       0          1\n",
       "725       0          1\n",
       "484       1          1\n",
       "685       0          0\n",
       "334       0          0\n",
       "627       0          0\n",
       "686       0          0\n",
       "264       1          0\n",
       "248       0          0\n",
       "99        1          0\n",
       "287       1          1\n",
       "611       1          1\n",
       "233       0          0\n",
       "722       1          0\n",
       "227       1          1\n",
       "310       0          0\n",
       "193       1          1\n",
       "440       1          0\n",
       "717       0          0\n",
       "462       0          0\n",
       "615       0          0\n",
       "174       0          0\n",
       "259       1          0\n",
       "512       0          0\n",
       "111       1          1\n",
       "548       0          1\n",
       "680       0          0\n",
       "\n",
       "[231 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparsion_df=pd.DataFrame({'actual': y_test, 'predicted':predict_model})\n",
    "comparsion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, f1_score,recall_score,roc_auc_score,roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[106,  44],\n",
       "       [ 39,  42]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,predict_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4883720930232558"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,predict_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5029940119760479"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,predict_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5185185185185185"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,predict_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc=roc_auc_score(y_test,predict_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba=decision_tree.predict_proba(X_test)[::,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr,tpr,thresholds=roc_curve(y_test,y_pred_proba)\n",
    "auc=roc_auc_score(y_test,y_pred_proba)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr,tpr,label=\"auc=\"+str(auc))\n",
    "plt.xlabel(\"false positive rate\")\n",
    "plt.ylabel(\"true positive rate\")\n",
    "plt.title('AUC-ROC curve')\n",
    "plt.legend(loc=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>Proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     predicted  Proba\n",
       "0            1    1.0\n",
       "1            0    0.0\n",
       "2            1    1.0\n",
       "3            0    0.0\n",
       "4            0    0.0\n",
       "5            1    1.0\n",
       "6            1    1.0\n",
       "7            1    1.0\n",
       "8            1    1.0\n",
       "9            0    0.0\n",
       "10           0    0.0\n",
       "11           1    1.0\n",
       "12           1    1.0\n",
       "13           0    0.0\n",
       "14           1    1.0\n",
       "15           0    0.0\n",
       "16           0    0.0\n",
       "17           1    1.0\n",
       "18           1    1.0\n",
       "19           0    0.0\n",
       "20           0    0.0\n",
       "21           0    0.0\n",
       "22           1    1.0\n",
       "23           1    1.0\n",
       "24           0    0.0\n",
       "25           1    1.0\n",
       "26           1    1.0\n",
       "27           1    1.0\n",
       "28           0    0.0\n",
       "29           1    1.0\n",
       "..         ...    ...\n",
       "201          1    1.0\n",
       "202          0    0.0\n",
       "203          0    0.0\n",
       "204          1    1.0\n",
       "205          1    1.0\n",
       "206          1    1.0\n",
       "207          0    0.0\n",
       "208          0    0.0\n",
       "209          0    0.0\n",
       "210          0    0.0\n",
       "211          0    0.0\n",
       "212          0    0.0\n",
       "213          0    0.0\n",
       "214          1    1.0\n",
       "215          1    1.0\n",
       "216          0    0.0\n",
       "217          0    0.0\n",
       "218          1    1.0\n",
       "219          0    0.0\n",
       "220          1    1.0\n",
       "221          0    0.0\n",
       "222          0    0.0\n",
       "223          1    1.0\n",
       "224          0    0.0\n",
       "225          0    0.0\n",
       "226          0    0.0\n",
       "227          0    0.0\n",
       "228          1    1.0\n",
       "229          1    1.0\n",
       "230          0    0.0\n",
       "\n",
       "[231 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df=pd.DataFrame({'predicted':predict_model, 'Proba':y_pred_proba})\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_depth=[4,5,6,7,8,9,10]\n",
    "Min_samples_split=[2,3,4,5,6,7]\n",
    "Criterion=['gini','entropy']\n",
    "Min_samples_leaf=[2,3,4,5,6,7,8]\n",
    "Splitter =['best','random']\n",
    "Max_leaf_nodes=[4,5,6,7,8,9,10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Para_dict = {'max_depth': Max_depth, \n",
    "             'min_samples_split': Min_samples_split, \n",
    "             'criterion': Criterion, \n",
    "             'min_samples_leaf': Min_samples_leaf,\n",
    "             'max_leaf_nodes': Max_leaf_nodes,\n",
    "             'n_estimators' : range(5,20)\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "Gd = GridSearchCV(decision_tree, Para_dict, cv=5, n_jobs=-1)\n",
    "Gd.fit(X_train,y_train)\n",
    "Gd.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7783985102420856"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gd.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'splitter': 'random',\n",
       " 'min_samples_split': 3,\n",
       " 'min_samples_leaf': 3,\n",
       " 'max_leaf_nodes': 9,\n",
       " 'max_depth': 10,\n",
       " 'criterion': 'gini'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "Rscv=RandomizedSearchCV(decision_tree, Para_dict,n_iter=12,cv=5,random_state=24 )\n",
    "Rscv.fit(X_train,y_train)\n",
    "Rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>0.247568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.160077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.144965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodPressure</th>\n",
       "      <td>0.112252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <td>0.109883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pregnancies</th>\n",
       "      <td>0.087467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insulin</th>\n",
       "      <td>0.075802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkinThickness</th>\n",
       "      <td>0.061986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Importance\n",
       "Glucose                     0.247568\n",
       "BMI                         0.160077\n",
       "Age                         0.144965\n",
       "BloodPressure               0.112252\n",
       "DiabetesPedigreeFunction    0.109883\n",
       "Pregnancies                 0.087467\n",
       "Insulin                     0.075802\n",
       "SkinThickness               0.061986"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFC = RandomForestClassifier(random_state=40,oob_score=True)\n",
    "RF_model=RFC.fit(X_train,y_train)\n",
    "importance= RFC.feature_importances_\n",
    "indicies= np.argsort(importance)\n",
    "\n",
    "var_importance=pd.DataFrame(importance,index=diabetes_df.columns,columns=['Importance'])\n",
    "var_importance=var_importance.sort_values(by='Importance',ascending=False)\n",
    "var_importance\n",
    "#predicted_RF_model=RFC.predict(X_test)\n",
    "#redicted_RF_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:458: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:463: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 8,\n",
       " 'min_samples_split': 4,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_leaf_nodes': 10,\n",
       " 'max_depth': 8,\n",
       " 'criterion': 'gini'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "Rscv=RandomizedSearchCV(RFC, Para_dict,n_iter=12,cv=5,random_state=24 )\n",
    "Rscv.fit(X_train,y_train)\n",
    "Rscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "GD_Params={'n_estimators': [10,20,15,25],\n",
    " 'min_samples_split': [2,3,4,5,6],\n",
    " 'min_samples_leaf': [3,4,5],\n",
    " 'max_leaf_nodes': [8,9,10,11,12],\n",
    " 'max_depth': [6,7,8,9],\n",
    " 'criterion': ['gini','entropy']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 6,\n",
       " 'max_leaf_nodes': 10,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 20}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "Gd = GridSearchCV(RFC, GD_Params, cv=5, n_jobs=-1)\n",
    "Gd.fit(X_train,y_train)\n",
    "Gd.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC_final = RandomForestClassifier(criterion= 'entropy', max_depth= 6, max_leaf_nodes= 10,min_samples_leaf= 4, min_samples_split= 2, n_estimators= 110,\n",
    "bootstrap=True, oob_score=True)\n",
    "RFC_final.fit(X_train,y_train)\n",
    "pred1=RFC_final.predict(X_test)\n",
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5935483870967742"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6231884057971014"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5308641975308642"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "Ada= AdaBoostClassifier(random_state=24)\n",
    "Ada.fit(X_train,y_train)\n",
    "Ada_predict=Ada.predict(X_test)\n",
    "Ada_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_params={'n_estimators':range(40,100),\n",
    "           'learning_rate':range(1,6)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1, 'n_estimators': 48}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "Gd = GridSearchCV(Ada, ada_params, cv=5, n_jobs=-1)\n",
    "Gd.fit(X_train,y_train)\n",
    "Gd.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ada_boost= AdaBoostClassifier(base_estimator=None,n_estimators=48,learning_rate=0.1,random_state=24,algorithm='SAMME.R')\n",
    "Ada_boost.fit(X_train,y_train)\n",
    "Ada_pred= Ada_boost.predict(X_test)\n",
    "Ada_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6399999999999999"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,Ada_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2154df05e48>]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "adaboost=AdaBoostClassifier(algorithm='SAMME')\n",
    "learning_rate=list(np.arange(0.1,1,0.1))\n",
    "f1_scores=[]\n",
    "for lr in learning_rate:\n",
    "    adaboost=AdaBoostClassifier(algorithm='SAMME',learning_rate=lr, n_estimators=20)\n",
    "    adaboost.fit(X_train,y_train)\n",
    "    y_ada_pred=adaboost.predict(X_test)\n",
    "    score=f1_score(y_test,y_ada_pred)\n",
    "    f1_scores.append(score)\n",
    "plt.plot(learning_rate,f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogR=LogisticRegression()\n",
    "LogR.fit(X_train,y_train)\n",
    "LogR_pre=LogR.predict(X_test)\n",
    "LogR_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.593103448275862"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,LogR_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.671875"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,LogR_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5308641975308642"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,LogR_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6954320987654321"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,LogR_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_proba1=LogR.predict_proba(X_test)[::,1]\n",
    "fpr,tpr,thresholds=roc_curve(y_test,y_pred_proba1)\n",
    "auc=roc_auc_score(y_test,y_pred_proba1)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr,tpr,label=\"auc=\"+str(auc))\n",
    "plt.xlabel(\"false positive rate\")\n",
    "plt.ylabel(\"true positive rate\")\n",
    "plt.title('AUC-ROC curve')\n",
    "plt.legend(loc=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.01234568, 0.03703704, 0.03703704, 0.12345679,\n",
       "        0.12345679, 0.16049383, 0.16049383, 0.25925926, 0.25925926,\n",
       "        0.37037037, 0.37037037, 0.40740741, 0.40740741, 0.41975309,\n",
       "        0.41975309, 0.45679012, 0.45679012, 0.4691358 , 0.4691358 ,\n",
       "        0.48148148, 0.48148148, 0.51851852, 0.51851852, 0.5308642 ,\n",
       "        0.5308642 , 0.54320988, 0.54320988, 0.56790123, 0.56790123,\n",
       "        0.58024691, 0.58024691, 0.65432099, 0.65432099, 0.66666667,\n",
       "        0.66666667, 0.69135802, 0.69135802, 0.71604938, 0.71604938,\n",
       "        0.74074074, 0.74074074, 0.75308642, 0.75308642, 0.7654321 ,\n",
       "        0.7654321 , 0.77777778, 0.77777778, 0.79012346, 0.79012346,\n",
       "        0.80246914, 0.80246914, 0.81481481, 0.81481481, 0.82716049,\n",
       "        0.82716049, 0.83950617, 0.83950617, 0.85185185, 0.85185185,\n",
       "        0.86419753, 0.86419753, 0.87654321, 0.87654321, 0.88888889,\n",
       "        0.88888889, 0.90123457, 0.90123457, 0.91358025, 0.91358025,\n",
       "        0.92592593, 0.92592593, 0.9382716 , 0.9382716 , 0.96296296,\n",
       "        0.96296296, 0.97530864, 0.97530864, 0.98765432, 0.98765432,\n",
       "        1.        , 1.        ]),\n",
       " array([0.        , 0.        , 0.        , 0.00666667, 0.00666667,\n",
       "        0.01333333, 0.01333333, 0.02      , 0.02      , 0.04      ,\n",
       "        0.04      , 0.05333333, 0.05333333, 0.06666667, 0.06666667,\n",
       "        0.07333333, 0.07333333, 0.08      , 0.08      , 0.08666667,\n",
       "        0.08666667, 0.1       , 0.1       , 0.12666667, 0.12666667,\n",
       "        0.14      , 0.14      , 0.14666667, 0.14666667, 0.15333333,\n",
       "        0.15333333, 0.2       , 0.2       , 0.20666667, 0.20666667,\n",
       "        0.21333333, 0.21333333, 0.22      , 0.22      , 0.22666667,\n",
       "        0.22666667, 0.24      , 0.24      , 0.26      , 0.26      ,\n",
       "        0.27333333, 0.27333333, 0.28666667, 0.28666667, 0.3       ,\n",
       "        0.3       , 0.33333333, 0.33333333, 0.37333333, 0.37333333,\n",
       "        0.42666667, 0.42666667, 0.44      , 0.44      , 0.45333333,\n",
       "        0.45333333, 0.46666667, 0.46666667, 0.5       , 0.5       ,\n",
       "        0.50666667, 0.50666667, 0.52      , 0.52      , 0.55333333,\n",
       "        0.55333333, 0.58      , 0.58      , 0.62666667, 0.62666667,\n",
       "        0.69333333, 0.69333333, 0.7       , 0.7       , 0.85333333,\n",
       "        0.85333333, 1.        ]),\n",
       " array([1.97289209, 0.97289209, 0.934554  , 0.91498155, 0.86320115,\n",
       "        0.85093195, 0.82100329, 0.8174087 , 0.77876979, 0.74523898,\n",
       "        0.69214503, 0.68237778, 0.65408988, 0.63894237, 0.63274022,\n",
       "        0.61836278, 0.61139473, 0.60760448, 0.60610089, 0.60590986,\n",
       "        0.58561057, 0.58481596, 0.56733388, 0.52464329, 0.51936411,\n",
       "        0.5081373 , 0.49762469, 0.4947719 , 0.4841648 , 0.4779522 ,\n",
       "        0.47148942, 0.45385818, 0.40854845, 0.40539055, 0.40319239,\n",
       "        0.40074795, 0.39151881, 0.38966108, 0.38910151, 0.38438217,\n",
       "        0.37461959, 0.37284396, 0.3714394 , 0.36137715, 0.35807405,\n",
       "        0.35349704, 0.35031895, 0.34795056, 0.34773079, 0.34423403,\n",
       "        0.34381878, 0.33818211, 0.33782305, 0.30811024, 0.30537758,\n",
       "        0.27528455, 0.27527583, 0.26660714, 0.26549617, 0.25941666,\n",
       "        0.2590665 , 0.25380149, 0.25229009, 0.24305605, 0.24218737,\n",
       "        0.23960365, 0.23916313, 0.23555657, 0.23437216, 0.22896378,\n",
       "        0.22566142, 0.21912781, 0.21405498, 0.20021316, 0.19344366,\n",
       "        0.17927192, 0.17750471, 0.17619629, 0.17566274, 0.12377459,\n",
       "        0.12290898, 0.03633088]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr,fpr,thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
